{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mod3b_new1_es.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "IoPLl4wl5ChQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04cef657-f044-4a59-aa9a-4a2b41f8b864"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras import Sequential\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense\n",
        "from keras import regularizers\n",
        "from keras.layers import Dropout\n",
        "from keras.constraints import max_norm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "VezhLbAl5hlf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee500069-2cbd-4aea-8f71-8bfd81ba8408"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IfyWKzso5kW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/My Drive/Santander_Kaggle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0zxGMgAj54rQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y7m-ZgZL557b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6a6291c-5eff-42fe-f55d-093cdb41e82f"
      },
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 202)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "O6Hqpg2S5775",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae874b11-d76e-483e-ff09-106021366e32"
      },
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 201)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "wGpLZyjJ6Fqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4f73e3b0-4d2c-4290-fa9e-448b86ea186f"
      },
      "cell_type": "code",
      "source": [
        "#Check num of cases in label \n",
        "print(train.target.value_counts())\n",
        "print(train.target.value_counts()[1]/train.target.value_counts()[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    179902\n",
            "1     20098\n",
            "Name: target, dtype: int64\n",
            "0.1117163789174106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T46AmHcf6Nna",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Very imbalanced data - only 11% target values are 1s, rest are 0s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8iJa03HG5hiX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_features = train.drop(['target', 'ID_code'], axis=1)\n",
        "train_targets = train['target']\n",
        "test_features = test.drop(['ID_code'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y2N_no6P5kLM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_targets, test_size = 0.25, random_state = 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cHqlfFZ86abh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "test_features = sc.transform(test_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-iD9-_Bv6gkG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Feature selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rnvoAu7I6ys_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "b25c956e-54e5-4228-978e-9a0872eb193c"
      },
      "cell_type": "code",
      "source": [
        "sfm = SelectFromModel(LassoCV())\n",
        "sfm.fit(X_train, y_train)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=LassoCV(alphas=None, copy_X=True, cv='warn', eps=0.001, fit_intercept=True,\n",
              "    max_iter=1000, n_alphas=100, n_jobs=None, normalize=False,\n",
              "    positive=False, precompute='auto', random_state=None,\n",
              "    selection='cyclic', tol=0.0001, verbose=False),\n",
              "        max_features=None, norm_order=1, prefit=False, threshold=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "WO7fZ1rt9SE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "e1664b10-e5cf-4e6e-9262-13620237e010"
      },
      "cell_type": "code",
      "source": [
        "# Feature selection using logistic regression\n",
        "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l1\"), '1.25*median')\n",
        "embeded_lr_selector.fit(X_train, y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
              "          tol=0.0001, verbose=0, warm_start=False),\n",
              "        max_features=None, norm_order=1, prefit=False,\n",
              "        threshold='1.25*median')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "aLKgtsoC61k6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = embeded_lr_selector.transform(X_train)\n",
        "X_test = embeded_lr_selector.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WSfXsNjm7Dvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1af28ba3-79d2-4239-d7b2-2b3d143ce0a9"
      },
      "cell_type": "code",
      "source": [
        "print('Number of features : %d' % X_train.shape[1])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of features : 73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Eej8Zs2P7Fvq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85c38415-0f0f-459b-8311-52b9ff5bccda"
      },
      "cell_type": "code",
      "source": [
        "print('Number of features in test : %d' % X_test.shape[1])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of features in test : 73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ky9haSFO91VV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Add RUC metric to monitor NN\n",
        "\n",
        "def auc(y_true, y_pred):\n",
        "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
        "    K.get_session().run(tf.local_variables_initializer())\n",
        "    return auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d8ieVX1v-OoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94dcb2ba-543f-4bc3-f79d-56f908c29ab7"
      },
      "cell_type": "code",
      "source": [
        "input_dim = X_train.shape[1]\n",
        "input_dim"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "74Lx1xtcpP7M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Try early stopping\n",
        "from keras.callbacks import EarlyStopping\n",
        "callback = EarlyStopping(monitor='val_auc', min_delta=0.000001, patience=2, verbose=0, mode='max', baseline=None, restore_best_weights=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZCSYiNno-Uq4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "e1132c82-9af0-41c3-fe42-f6ddd13468bc"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# Input layer\n",
        "#model.add(Dense(units = 200, activation = \"relu\", input_dim = input_dim, kernel_initializer = \"uniform\", kernel_regularizer=regularizers.l2(0.005)))\n",
        "model.add(Dense(units = 200, activation = \"relu\", input_dim = input_dim, kernel_initializer = \"normal\", kernel_regularizer=regularizers.l2(0.005), \n",
        "                kernel_constraint = max_norm(5.)))\n",
        "# Add dropout regularization\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "# First hidden layer\n",
        "model.add(Dense(units = 200, activation='relu', kernel_regularizer=regularizers.l2(0.005), kernel_constraint=max_norm(5)))\n",
        "# Add dropout regularization\n",
        "model.add(Dropout(rate=0.1))\n",
        "\n",
        "#input_dim=input_dim\n",
        "\n",
        "# Second hidden layer\n",
        "model.add(Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.005), kernel_constraint=max_norm(5)))\n",
        "# Add dropout regularization\n",
        "model.add(Dropout(rate=0.1))\n",
        "\n",
        "# Third hidden layer\n",
        "model.add(Dense(50, activation='tanh', kernel_regularizer=regularizers.l2(0.005), kernel_constraint=max_norm(5)))\n",
        "# Add dropout regularization\n",
        "model.add(Dropout(rate=0.1))\n",
        "\n",
        "# Fourth hidden layer\n",
        "#model.add(Dense(25, activation='tanh', kernel_regularizer=regularizers.l2(0.005)))\n",
        "# Add dropout regularization\n",
        "#model.add(Dropout(rate=0.1))\n",
        "\n",
        "# Output layer\n",
        "model.add(layers.Dense(units = 1, activation='sigmoid'))\n",
        "\n",
        "#model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', auc])\n",
        "model.summary()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_96 (Dense)             (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dropout_77 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dropout_78 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_79 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_99 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_80 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_100 (Dense)            (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 105,601\n",
            "Trainable params: 105,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XpOMvHHO_Idn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4321
        },
        "outputId": "6bd8e202-bb6c-4706-f701-d50ddb0e174e"
      },
      "cell_type": "code",
      "source": [
        "#batch_size = 20,\n",
        "model.fit(X_train, y_train, batch_size = 16384, epochs = 125, validation_data = (X_test, y_test), callbacks = [callback])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 150000 samples, validate on 50000 samples\n",
            "Epoch 1/125\n",
            "150000/150000 [==============================] - 11s 71us/step - loss: 2.8686 - acc: 0.8039 - auc: 0.5014 - val_loss: 2.6124 - val_acc: 0.8990 - val_auc: 0.5164\n",
            "Epoch 2/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 2.4535 - acc: 0.8997 - auc: 0.5414 - val_loss: 2.2355 - val_acc: 0.8990 - val_auc: 0.5596\n",
            "Epoch 3/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 2.1159 - acc: 0.8997 - auc: 0.5753 - val_loss: 1.9338 - val_acc: 0.8990 - val_auc: 0.5960\n",
            "Epoch 4/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 1.8209 - acc: 0.8997 - auc: 0.6203 - val_loss: 1.6625 - val_acc: 0.8990 - val_auc: 0.6455\n",
            "Epoch 5/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 1.5700 - acc: 0.8997 - auc: 0.6670 - val_loss: 1.4371 - val_acc: 0.8990 - val_auc: 0.6858\n",
            "Epoch 6/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 1.3589 - acc: 0.8997 - auc: 0.7013 - val_loss: 1.2502 - val_acc: 0.8990 - val_auc: 0.7148\n",
            "Epoch 7/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 1.1837 - acc: 0.9000 - auc: 0.7263 - val_loss: 1.0945 - val_acc: 0.9000 - val_auc: 0.7362\n",
            "Epoch 8/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 1.0378 - acc: 0.9015 - auc: 0.7448 - val_loss: 0.9650 - val_acc: 0.9047 - val_auc: 0.7523\n",
            "Epoch 9/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.9165 - acc: 0.9051 - auc: 0.7589 - val_loss: 0.8576 - val_acc: 0.9082 - val_auc: 0.7648\n",
            "Epoch 10/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.8156 - acc: 0.9079 - auc: 0.7702 - val_loss: 0.7681 - val_acc: 0.9109 - val_auc: 0.7749\n",
            "Epoch 11/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.7317 - acc: 0.9106 - auc: 0.7793 - val_loss: 0.6936 - val_acc: 0.9116 - val_auc: 0.7832\n",
            "Epoch 12/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.6616 - acc: 0.9118 - auc: 0.7869 - val_loss: 0.6311 - val_acc: 0.9116 - val_auc: 0.7901\n",
            "Epoch 13/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.6033 - acc: 0.9126 - auc: 0.7933 - val_loss: 0.5796 - val_acc: 0.9115 - val_auc: 0.7960\n",
            "Epoch 14/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.5544 - acc: 0.9131 - auc: 0.7987 - val_loss: 0.5355 - val_acc: 0.9116 - val_auc: 0.8011\n",
            "Epoch 15/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.5137 - acc: 0.9133 - auc: 0.8034 - val_loss: 0.4987 - val_acc: 0.9118 - val_auc: 0.8054\n",
            "Epoch 16/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.4795 - acc: 0.9141 - auc: 0.8074 - val_loss: 0.4682 - val_acc: 0.9119 - val_auc: 0.8092\n",
            "Epoch 17/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.4507 - acc: 0.9137 - auc: 0.8109 - val_loss: 0.4415 - val_acc: 0.9125 - val_auc: 0.8125\n",
            "Epoch 18/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.4261 - acc: 0.9148 - auc: 0.8141 - val_loss: 0.4195 - val_acc: 0.9122 - val_auc: 0.8154\n",
            "Epoch 19/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.4055 - acc: 0.9144 - auc: 0.8168 - val_loss: 0.4002 - val_acc: 0.9121 - val_auc: 0.8180\n",
            "Epoch 20/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.3877 - acc: 0.9142 - auc: 0.8193 - val_loss: 0.3833 - val_acc: 0.9125 - val_auc: 0.8203\n",
            "Epoch 21/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.3731 - acc: 0.9145 - auc: 0.8215 - val_loss: 0.3700 - val_acc: 0.9122 - val_auc: 0.8224\n",
            "Epoch 22/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.3596 - acc: 0.9152 - auc: 0.8233 - val_loss: 0.3572 - val_acc: 0.9122 - val_auc: 0.8242\n",
            "Epoch 23/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.3487 - acc: 0.9147 - auc: 0.8251 - val_loss: 0.3470 - val_acc: 0.9125 - val_auc: 0.8259\n",
            "Epoch 24/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.3392 - acc: 0.9147 - auc: 0.8267 - val_loss: 0.3378 - val_acc: 0.9125 - val_auc: 0.8274\n",
            "Epoch 25/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.3306 - acc: 0.9144 - auc: 0.8281 - val_loss: 0.3300 - val_acc: 0.9127 - val_auc: 0.8287\n",
            "Epoch 26/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.3233 - acc: 0.9147 - auc: 0.8294 - val_loss: 0.3227 - val_acc: 0.9127 - val_auc: 0.8300\n",
            "Epoch 27/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.3164 - acc: 0.9145 - auc: 0.8306 - val_loss: 0.3164 - val_acc: 0.9127 - val_auc: 0.8311\n",
            "Epoch 28/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.3107 - acc: 0.9147 - auc: 0.8317 - val_loss: 0.3106 - val_acc: 0.9130 - val_auc: 0.8322\n",
            "Epoch 29/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.3054 - acc: 0.9149 - auc: 0.8327 - val_loss: 0.3065 - val_acc: 0.9122 - val_auc: 0.8332\n",
            "Epoch 30/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.3010 - acc: 0.9148 - auc: 0.8337 - val_loss: 0.3016 - val_acc: 0.9123 - val_auc: 0.8341\n",
            "Epoch 31/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2971 - acc: 0.9147 - auc: 0.8345 - val_loss: 0.2979 - val_acc: 0.9127 - val_auc: 0.8349\n",
            "Epoch 32/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2933 - acc: 0.9147 - auc: 0.8353 - val_loss: 0.2940 - val_acc: 0.9130 - val_auc: 0.8357\n",
            "Epoch 33/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2901 - acc: 0.9149 - auc: 0.8361 - val_loss: 0.2911 - val_acc: 0.9123 - val_auc: 0.8364\n",
            "Epoch 34/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2872 - acc: 0.9144 - auc: 0.8368 - val_loss: 0.2883 - val_acc: 0.9128 - val_auc: 0.8371\n",
            "Epoch 35/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2846 - acc: 0.9151 - auc: 0.8374 - val_loss: 0.2852 - val_acc: 0.9128 - val_auc: 0.8377\n",
            "Epoch 36/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2821 - acc: 0.9146 - auc: 0.8380 - val_loss: 0.2830 - val_acc: 0.9132 - val_auc: 0.8383\n",
            "Epoch 37/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2799 - acc: 0.9149 - auc: 0.8386 - val_loss: 0.2809 - val_acc: 0.9129 - val_auc: 0.8389\n",
            "Epoch 38/125\n",
            "150000/150000 [==============================] - 6s 42us/step - loss: 0.2776 - acc: 0.9149 - auc: 0.8392 - val_loss: 0.2784 - val_acc: 0.9136 - val_auc: 0.8394\n",
            "Epoch 39/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2756 - acc: 0.9145 - auc: 0.8397 - val_loss: 0.2768 - val_acc: 0.9125 - val_auc: 0.8399\n",
            "Epoch 40/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2737 - acc: 0.9150 - auc: 0.8402 - val_loss: 0.2753 - val_acc: 0.9128 - val_auc: 0.8404\n",
            "Epoch 41/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2726 - acc: 0.9144 - auc: 0.8406 - val_loss: 0.2732 - val_acc: 0.9127 - val_auc: 0.8409\n",
            "Epoch 42/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2709 - acc: 0.9151 - auc: 0.8411 - val_loss: 0.2722 - val_acc: 0.9128 - val_auc: 0.8413\n",
            "Epoch 43/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2696 - acc: 0.9151 - auc: 0.8415 - val_loss: 0.2709 - val_acc: 0.9131 - val_auc: 0.8417\n",
            "Epoch 44/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2686 - acc: 0.9151 - auc: 0.8419 - val_loss: 0.2695 - val_acc: 0.9130 - val_auc: 0.8421\n",
            "Epoch 45/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2676 - acc: 0.9145 - auc: 0.8423 - val_loss: 0.2692 - val_acc: 0.9128 - val_auc: 0.8425\n",
            "Epoch 46/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2663 - acc: 0.9152 - auc: 0.8427 - val_loss: 0.2679 - val_acc: 0.9133 - val_auc: 0.8428\n",
            "Epoch 47/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2655 - acc: 0.9153 - auc: 0.8430 - val_loss: 0.2667 - val_acc: 0.9130 - val_auc: 0.8432\n",
            "Epoch 48/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2646 - acc: 0.9144 - auc: 0.8433 - val_loss: 0.2658 - val_acc: 0.9128 - val_auc: 0.8435\n",
            "Epoch 49/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2641 - acc: 0.9149 - auc: 0.8436 - val_loss: 0.2653 - val_acc: 0.9134 - val_auc: 0.8438\n",
            "Epoch 50/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2629 - acc: 0.9153 - auc: 0.8440 - val_loss: 0.2641 - val_acc: 0.9129 - val_auc: 0.8441\n",
            "Epoch 51/125\n",
            "150000/150000 [==============================] - 6s 42us/step - loss: 0.2624 - acc: 0.9148 - auc: 0.8442 - val_loss: 0.2636 - val_acc: 0.9132 - val_auc: 0.8444\n",
            "Epoch 52/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2617 - acc: 0.9150 - auc: 0.8445 - val_loss: 0.2633 - val_acc: 0.9127 - val_auc: 0.8447\n",
            "Epoch 53/125\n",
            "150000/150000 [==============================] - 6s 40us/step - loss: 0.2614 - acc: 0.9146 - auc: 0.8448 - val_loss: 0.2624 - val_acc: 0.9132 - val_auc: 0.8449\n",
            "Epoch 54/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2607 - acc: 0.9147 - auc: 0.8450 - val_loss: 0.2621 - val_acc: 0.9127 - val_auc: 0.8452\n",
            "Epoch 55/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2598 - acc: 0.9152 - auc: 0.8453 - val_loss: 0.2613 - val_acc: 0.9132 - val_auc: 0.8454\n",
            "Epoch 56/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2598 - acc: 0.9147 - auc: 0.8455 - val_loss: 0.2606 - val_acc: 0.9132 - val_auc: 0.8456\n",
            "Epoch 57/125\n",
            "150000/150000 [==============================] - 6s 42us/step - loss: 0.2591 - acc: 0.9147 - auc: 0.8457 - val_loss: 0.2600 - val_acc: 0.9131 - val_auc: 0.8459\n",
            "Epoch 58/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2586 - acc: 0.9151 - auc: 0.8460 - val_loss: 0.2604 - val_acc: 0.9130 - val_auc: 0.8461\n",
            "Epoch 59/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2585 - acc: 0.9147 - auc: 0.8462 - val_loss: 0.2593 - val_acc: 0.9130 - val_auc: 0.8463\n",
            "Epoch 60/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2581 - acc: 0.9151 - auc: 0.8464 - val_loss: 0.2592 - val_acc: 0.9127 - val_auc: 0.8465\n",
            "Epoch 61/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2573 - acc: 0.9144 - auc: 0.8466 - val_loss: 0.2587 - val_acc: 0.9135 - val_auc: 0.8467\n",
            "Epoch 62/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2568 - acc: 0.9150 - auc: 0.8468 - val_loss: 0.2584 - val_acc: 0.9131 - val_auc: 0.8469\n",
            "Epoch 63/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2565 - acc: 0.9146 - auc: 0.8470 - val_loss: 0.2577 - val_acc: 0.9131 - val_auc: 0.8471\n",
            "Epoch 64/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2563 - acc: 0.9146 - auc: 0.8472 - val_loss: 0.2582 - val_acc: 0.9131 - val_auc: 0.8473\n",
            "Epoch 65/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2559 - acc: 0.9150 - auc: 0.8474 - val_loss: 0.2578 - val_acc: 0.9131 - val_auc: 0.8474\n",
            "Epoch 66/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2559 - acc: 0.9149 - auc: 0.8475 - val_loss: 0.2566 - val_acc: 0.9131 - val_auc: 0.8476\n",
            "Epoch 67/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2556 - acc: 0.9149 - auc: 0.8477 - val_loss: 0.2569 - val_acc: 0.9134 - val_auc: 0.8478\n",
            "Epoch 68/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2552 - acc: 0.9149 - auc: 0.8479 - val_loss: 0.2565 - val_acc: 0.9138 - val_auc: 0.8479\n",
            "Epoch 69/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2548 - acc: 0.9149 - auc: 0.8480 - val_loss: 0.2565 - val_acc: 0.9127 - val_auc: 0.8481\n",
            "Epoch 70/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2548 - acc: 0.9150 - auc: 0.8482 - val_loss: 0.2565 - val_acc: 0.9130 - val_auc: 0.8483\n",
            "Epoch 71/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2550 - acc: 0.9143 - auc: 0.8483 - val_loss: 0.2567 - val_acc: 0.9129 - val_auc: 0.8484\n",
            "Epoch 72/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2544 - acc: 0.9146 - auc: 0.8485 - val_loss: 0.2559 - val_acc: 0.9137 - val_auc: 0.8485\n",
            "Epoch 73/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2541 - acc: 0.9151 - auc: 0.8486 - val_loss: 0.2560 - val_acc: 0.9132 - val_auc: 0.8487\n",
            "Epoch 74/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2537 - acc: 0.9148 - auc: 0.8488 - val_loss: 0.2561 - val_acc: 0.9130 - val_auc: 0.8488\n",
            "Epoch 75/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2537 - acc: 0.9148 - auc: 0.8489 - val_loss: 0.2553 - val_acc: 0.9138 - val_auc: 0.8489\n",
            "Epoch 76/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2541 - acc: 0.9146 - auc: 0.8490 - val_loss: 0.2552 - val_acc: 0.9129 - val_auc: 0.8491\n",
            "Epoch 77/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2535 - acc: 0.9147 - auc: 0.8491 - val_loss: 0.2553 - val_acc: 0.9130 - val_auc: 0.8492\n",
            "Epoch 78/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2535 - acc: 0.9147 - auc: 0.8493 - val_loss: 0.2543 - val_acc: 0.9133 - val_auc: 0.8493\n",
            "Epoch 79/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2528 - acc: 0.9149 - auc: 0.8494 - val_loss: 0.2545 - val_acc: 0.9132 - val_auc: 0.8495\n",
            "Epoch 80/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2532 - acc: 0.9149 - auc: 0.8495 - val_loss: 0.2547 - val_acc: 0.9134 - val_auc: 0.8496\n",
            "Epoch 81/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2531 - acc: 0.9148 - auc: 0.8496 - val_loss: 0.2544 - val_acc: 0.9133 - val_auc: 0.8497\n",
            "Epoch 82/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2527 - acc: 0.9149 - auc: 0.8498 - val_loss: 0.2547 - val_acc: 0.9129 - val_auc: 0.8498\n",
            "Epoch 83/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2527 - acc: 0.9147 - auc: 0.8499 - val_loss: 0.2545 - val_acc: 0.9133 - val_auc: 0.8499\n",
            "Epoch 84/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2528 - acc: 0.9147 - auc: 0.8500 - val_loss: 0.2541 - val_acc: 0.9132 - val_auc: 0.8500\n",
            "Epoch 85/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2524 - acc: 0.9148 - auc: 0.8501 - val_loss: 0.2543 - val_acc: 0.9134 - val_auc: 0.8502\n",
            "Epoch 86/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2526 - acc: 0.9146 - auc: 0.8502 - val_loss: 0.2536 - val_acc: 0.9133 - val_auc: 0.8503\n",
            "Epoch 87/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2524 - acc: 0.9149 - auc: 0.8503 - val_loss: 0.2544 - val_acc: 0.9131 - val_auc: 0.8504\n",
            "Epoch 88/125\n",
            "150000/150000 [==============================] - 6s 42us/step - loss: 0.2524 - acc: 0.9149 - auc: 0.8504 - val_loss: 0.2541 - val_acc: 0.9135 - val_auc: 0.8505\n",
            "Epoch 89/125\n",
            "150000/150000 [==============================] - 7s 43us/step - loss: 0.2524 - acc: 0.9148 - auc: 0.8505 - val_loss: 0.2544 - val_acc: 0.9133 - val_auc: 0.8506\n",
            "Epoch 90/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2522 - acc: 0.9149 - auc: 0.8506 - val_loss: 0.2539 - val_acc: 0.9128 - val_auc: 0.8507\n",
            "Epoch 91/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2519 - acc: 0.9149 - auc: 0.8507 - val_loss: 0.2545 - val_acc: 0.9129 - val_auc: 0.8508\n",
            "Epoch 92/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2520 - acc: 0.9147 - auc: 0.8508 - val_loss: 0.2540 - val_acc: 0.9131 - val_auc: 0.8508\n",
            "Epoch 93/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2517 - acc: 0.9147 - auc: 0.8509 - val_loss: 0.2532 - val_acc: 0.9135 - val_auc: 0.8509\n",
            "Epoch 94/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2517 - acc: 0.9145 - auc: 0.8510 - val_loss: 0.2534 - val_acc: 0.9133 - val_auc: 0.8510\n",
            "Epoch 95/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2520 - acc: 0.9142 - auc: 0.8511 - val_loss: 0.2538 - val_acc: 0.9132 - val_auc: 0.8511\n",
            "Epoch 96/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2518 - acc: 0.9145 - auc: 0.8512 - val_loss: 0.2534 - val_acc: 0.9131 - val_auc: 0.8512\n",
            "Epoch 97/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2513 - acc: 0.9150 - auc: 0.8512 - val_loss: 0.2533 - val_acc: 0.9134 - val_auc: 0.8513\n",
            "Epoch 98/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2509 - acc: 0.9152 - auc: 0.8513 - val_loss: 0.2533 - val_acc: 0.9131 - val_auc: 0.8514\n",
            "Epoch 99/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2513 - acc: 0.9145 - auc: 0.8514 - val_loss: 0.2534 - val_acc: 0.9127 - val_auc: 0.8515\n",
            "Epoch 100/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2512 - acc: 0.9147 - auc: 0.8515 - val_loss: 0.2534 - val_acc: 0.9136 - val_auc: 0.8516\n",
            "Epoch 101/125\n",
            "150000/150000 [==============================] - 6s 42us/step - loss: 0.2512 - acc: 0.9149 - auc: 0.8516 - val_loss: 0.2532 - val_acc: 0.9130 - val_auc: 0.8516\n",
            "Epoch 102/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2506 - acc: 0.9150 - auc: 0.8517 - val_loss: 0.2536 - val_acc: 0.9136 - val_auc: 0.8517\n",
            "Epoch 103/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2515 - acc: 0.9149 - auc: 0.8518 - val_loss: 0.2539 - val_acc: 0.9131 - val_auc: 0.8518\n",
            "Epoch 104/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2512 - acc: 0.9149 - auc: 0.8518 - val_loss: 0.2547 - val_acc: 0.9134 - val_auc: 0.8519\n",
            "Epoch 105/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2516 - acc: 0.9146 - auc: 0.8519 - val_loss: 0.2558 - val_acc: 0.9129 - val_auc: 0.8519\n",
            "Epoch 106/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2521 - acc: 0.9146 - auc: 0.8520 - val_loss: 0.2545 - val_acc: 0.9132 - val_auc: 0.8520\n",
            "Epoch 107/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2516 - acc: 0.9147 - auc: 0.8520 - val_loss: 0.2534 - val_acc: 0.9135 - val_auc: 0.8520\n",
            "Epoch 108/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2511 - acc: 0.9151 - auc: 0.8521 - val_loss: 0.2534 - val_acc: 0.9131 - val_auc: 0.8521\n",
            "Epoch 109/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2509 - acc: 0.9151 - auc: 0.8522 - val_loss: 0.2527 - val_acc: 0.9132 - val_auc: 0.8522\n",
            "Epoch 110/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2506 - acc: 0.9151 - auc: 0.8522 - val_loss: 0.2527 - val_acc: 0.9135 - val_auc: 0.8523\n",
            "Epoch 111/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2506 - acc: 0.9147 - auc: 0.8523 - val_loss: 0.2532 - val_acc: 0.9135 - val_auc: 0.8523\n",
            "Epoch 112/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2507 - acc: 0.9149 - auc: 0.8524 - val_loss: 0.2529 - val_acc: 0.9132 - val_auc: 0.8524\n",
            "Epoch 113/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2504 - acc: 0.9149 - auc: 0.8525 - val_loss: 0.2527 - val_acc: 0.9133 - val_auc: 0.8525\n",
            "Epoch 114/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2500 - acc: 0.9152 - auc: 0.8525 - val_loss: 0.2526 - val_acc: 0.9132 - val_auc: 0.8526\n",
            "Epoch 115/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2498 - acc: 0.9152 - auc: 0.8526 - val_loss: 0.2527 - val_acc: 0.9133 - val_auc: 0.8526\n",
            "Epoch 116/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2503 - acc: 0.9144 - auc: 0.8527 - val_loss: 0.2531 - val_acc: 0.9135 - val_auc: 0.8527\n",
            "Epoch 117/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2503 - acc: 0.9151 - auc: 0.8528 - val_loss: 0.2523 - val_acc: 0.9137 - val_auc: 0.8528\n",
            "Epoch 118/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2504 - acc: 0.9149 - auc: 0.8528 - val_loss: 0.2531 - val_acc: 0.9132 - val_auc: 0.8529\n",
            "Epoch 119/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2505 - acc: 0.9149 - auc: 0.8529 - val_loss: 0.2534 - val_acc: 0.9136 - val_auc: 0.8529\n",
            "Epoch 120/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2499 - acc: 0.9151 - auc: 0.8530 - val_loss: 0.2543 - val_acc: 0.9132 - val_auc: 0.8530\n",
            "Epoch 121/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2509 - acc: 0.9146 - auc: 0.8530 - val_loss: 0.2524 - val_acc: 0.9134 - val_auc: 0.8530\n",
            "Epoch 122/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2504 - acc: 0.9152 - auc: 0.8531 - val_loss: 0.2529 - val_acc: 0.9130 - val_auc: 0.8531\n",
            "Epoch 123/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2495 - acc: 0.9154 - auc: 0.8531 - val_loss: 0.2529 - val_acc: 0.9129 - val_auc: 0.8532\n",
            "Epoch 124/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2499 - acc: 0.9150 - auc: 0.8532 - val_loss: 0.2526 - val_acc: 0.9132 - val_auc: 0.8532\n",
            "Epoch 125/125\n",
            "150000/150000 [==============================] - 6s 41us/step - loss: 0.2497 - acc: 0.9149 - auc: 0.8533 - val_loss: 0.2522 - val_acc: 0.9130 - val_auc: 0.8533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbc91f394a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "hucuO9de_Sim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbb53114-e5b5-4953-9951-fac6081edb85"
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict_proba(X_test)\n",
        "roc_auc_score(y_test, y_pred)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8604632381777754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "F19khNVUAI9U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_and_save(model, filename):\n",
        "  id_code_test = test['ID_code']\n",
        "  # Make predicitions\n",
        "  pred = model.predict(test_features)\n",
        "  pred_ = pred[:,0]\n",
        "  fn = filename + \".csv\"\n",
        "  # To CSV\n",
        "  foo = pd.DataFrame({\"ID_code\" : id_code_test, \"target\" : pred_}).to_csv(fn, index = False, header = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YMce4ru1SiBr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_and_save(model, \"mod3b_new1_es\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8OERiTuvSqGi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}